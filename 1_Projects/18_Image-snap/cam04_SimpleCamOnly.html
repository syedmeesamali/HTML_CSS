<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport"
      content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<style>
.canvas2 { 
  position: fixed;
}
</style>
<title>Hand Track Simple Most</title>
</head>

<body>
<script src="https://cdn.jsdelivr.net/npm/handtrackjs/dist/handtrack.min.js"> </script>
<canvas id="canvas"></canvas>
<button onclick="toggleVideo()" id="trackbutton" type="button">Toggle Video</button>
<video width="320" height="240" autoplay="autoplay" id="myvideo"></video>
<div id="direction">--##--</div>

<canvas id="b" class="canvas2" width="1200" height="600"></canvas>

<script type="text/javascript">
const video = document.getElementById('myvideo');
const canvas = document.getElementById('canvas');
const b_canvas = document.getElementById('b');
var brush = b_canvas.getContext('2d');

//Make a rectangle with certain properties
function makeRect(x,y,wid,ht,fillStyle) {
        this.x = x; this.y = y; this.wid = wid; this.ht = ht;
        brush.clearRect(0, 0, b_canvas.width, b_canvas.height);
        brush.beginPath();
        brush.rect(x, y, wid, ht); //Draw the rectangle
        brush.strokeStyle = 'blue'; 
        brush.fillStyle = fillStyle;
        brush.fill();
    }

const dir = document.getElementById('direction');
const context = canvas.getContext('2d');
let trackButton = document.getElementById('trackbutton');

let [distx, disty] = [null, null]
let [ox, oy] = [0, 0]
let gestRecorded = true

let distOld = -1
let dif = 0
let gestureCount = 0

let isVideo = false;
let model = null;


const modelParams = {
  flipHorizontal: true,   // flip e.g for video 
  imageScaleFactor: 0.5,  // reduce input image size for gains in speed.
  maxNumBoxes: 2,        // maximum number of boxes to detect
  iouThreshold: 0.5,      // ioU threshold for non-max suppression
  scoreThreshold: 0.69,    // confidence threshold for predictions.
}

//Load the main model
handTrack.load(modelParams).then(newModel => {
    model = newModel;
    trackButton.disabled = false;
});

//Start or stop the video
function toggleVideo() {
    if (!isVideo) {
        console.log("Starting video..");
        startVideo();
    } else {
      console.log("Stopping video..");
        handTrack.stopVideo(video)
        isVideo = false;
        console.log("STopped!");
    }
}


//Begin the main video
function beginVideo() {
    handTrack.startVideo(video).then(function(status) {
      if(status) {
        isVideo = true;
        runDetection();
      }
    })
}

//Start the main video
function startVideo() {
    handTrack.startVideo(video).then(function (status) {
        console.log("video started", status);
        if (status) {
            isVideo = true
            runDetection()
        } else {
          console.log("Please enable video ......");
        }
    });
}

//Direction of movement
const getDirection = predictions => {
  let direction = ''
  const p1x1 = parseInt(predictions[0].bbox[0])
  const p1y1 = parseInt(predictions[0].bbox[1])
  const p1x2 = parseInt(predictions[0].bbox[2])
  const p1y2 = parseInt(predictions[0].bbox[3])
  const [x, y] = [(p1x1 + p1x2) / 2, (p1y1 + p1y2) / 2] //center points for the hand

  if (gestRecorded) {
    ox = x
    oy = y
    gestRecorded = false
  } else {
    distx = x - ox
    disty = y - oy
    if (Math.abs(distx) > 10 || Math.abs(disty) > 10) {
      gestRecorded = true
      direction = Math.abs(distx) > Math.abs(disty) ? distx > 0  ? 'right' : 'left' : disty > 0 ? 'down' : 'up'
    }
  }
  return direction
}

x = 50; y = 50;
makeRect(x, y, 200, 40, "red");    
//Run the detection in browser
function runDetection() {
    model.detect(video).then(predictions => {        
        if (predictions.length >= 1) {
              dir.innerText = getDirection(predictions);
              if (dir.innerText === "right") {
                x = x + 50;
                console.log("x: " + x + " , y is: " + y);
                makeRect(x, y, 100, y - 10, "Blue");  
              } else if (dir.innerText === "left") {
                x = x - 50;
                makeRect(x, y, 100, y - 10, "Blue");
                console.log("x: " + x + " , y is: " + y);
              }
              model.renderPredictions(predictions, canvas, context, video);    
            }
      
            if (isVideo) {
                requestAnimationFrame(runDetection)
            } else {
              handTrack.stopVideo(video)
            }
    })
}

/*handTrack.load(modelParams).then(model => {
  model.detect(img).then(predictions => {
    console.log("Predictions: ", predictions);
        if (predictions.length > 0.65) {
            const x = predictions[0].bbox[0];
            const y = predictions[0].bbox[1];
            const width = predictions[0].bbox[2];
            const height = predictions[0].bbox[3];
        } 
  });//End of model load
}); //End of hand track

var constraints = { audio: false, video: { width: 640, height: 480 } };
navigator.mediaDevices.getUserMedia(constraints)
.then(function(mediaStream) {
  var video = document.querySelector('video');
  video.srcObject = mediaStream;
  video.onloadedmetadata = function(e) {  video.play();   };
}).catch(function(err) { console.log(err.name + ": " + err.message); })*/

</script>
</body>
</html>